{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8f28c68-e5c7-4cae-9e89-1903f4f08601",
   "metadata": {},
   "source": [
    "#### 1. Importing libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "83c75cb8-5dd8-4273-9571-28a1290e0bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rimay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#NLTK libraries\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "73667fde-c9e0-47b7-a59f-0e942347f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the datasets\n",
    "\n",
    "df_onion = pd.read_csv('./theonion.csv') # fake news\n",
    "df_not_onion = pd.read_csv('./nottheonion.csv') # true news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "01486de1-4518-48d9-a591-bf15f1c77a88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the  data is (row, column):(1343, 7)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1343 entries, 0 to 1342\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   subreddit     1343 non-null   object\n",
      " 1   author        1343 non-null   object\n",
      " 2   domain        1343 non-null   object\n",
      " 3   title         1343 non-null   object\n",
      " 4   num_comments  1343 non-null   int64 \n",
      " 5   score         1343 non-null   int64 \n",
      " 6   timestamp     1343 non-null   int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 73.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print shape of the datasets - fake news\n",
    "\n",
    "print (\"The shape of the  data is (row, column):\"+ str(df_onion.shape))\n",
    "print (df_onion.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "255c0499-d209-43c6-95c2-ffa0750cda2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the  data is (row, column):(9997, 7)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9997 entries, 0 to 9996\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   subreddit     9997 non-null   object\n",
      " 1   author        9997 non-null   object\n",
      " 2   domain        9997 non-null   object\n",
      " 3   title         9997 non-null   object\n",
      " 4   num_comments  9997 non-null   int64 \n",
      " 5   score         9997 non-null   int64 \n",
      " 6   timestamp     9997 non-null   int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 546.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print shape of the datasets - True news\n",
    "\n",
    "print (\"The shape of the  data is (row, column):\"+ str(df_not_onion.shape))\n",
    "print (df_not_onion.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe4bfc2-ac8a-4a3b-b47f-052ed71673d0",
   "metadata": {},
   "source": [
    "From the information above, the dataset contain 1,343 of fake news while other dataset consist of 9,997 true news for the period 1 January 2021 to 31 December 2021.\n",
    "\n",
    "Description of columns:\n",
    "\n",
    "* Subreddit - forum of the topic of `r/theonion` or `r/nottheonion`\n",
    "* author - the person who make the post\n",
    "* domain - the url link to the contains of the news\n",
    "* title - contains the news headlines\n",
    "* num_comments - no. of comments made by the readers\n",
    "* score - number of upvotes minus the number of downvotes\n",
    "* timestamp - the date of the news posted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c935156-8698-4f84-b8a1-5a3ad835b3ec",
   "metadata": {},
   "source": [
    "#### 2. Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24592b8-cd2f-46f9-8697-b69b94d64745",
   "metadata": {},
   "source": [
    "We need to perform the following text cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa95a8a-1f19-4f9d-b98e-42e1437dadb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 2a. Checking the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "996c5b33-0465-43e0-a445-8b331b8e33e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheOnion start date: 2021-01-01\n",
      "TheOnion end date: 2021-12-31\n",
      "Nottheonion start date: 2021-10-29\n",
      "Nottheonion end date: 2021-12-31\n"
     ]
    }
   ],
   "source": [
    "# Convert Unix Timestamp to Datetime\n",
    "df_onion['timestamp'] = pd.to_datetime(df_onion['timestamp'], unit='s').dt.date\n",
    "df_not_onion['timestamp'] = pd.to_datetime(df_not_onion['timestamp'], unit='s').dt.date\n",
    "\n",
    "# Show date-range of posts scraped from r/TheOnion and r/nottheonion\n",
    "print(\"TheOnion start date:\", df_onion['timestamp'].min())\n",
    "print(\"TheOnion end date:\", df_onion['timestamp'].max())\n",
    "print(\"Nottheonion start date:\", df_not_onion['timestamp'].min())\n",
    "print(\"Nottheonion end date:\", df_not_onion['timestamp'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "586c8c60-80a9-4891-b77a-00d09a20c453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TheOnion</th>\n",
       "      <th>notheonion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domain</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_comments</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TheOnion  notheonion\n",
       "subreddit            0           0\n",
       "author               0           0\n",
       "domain               0           0\n",
       "title                0           0\n",
       "num_comments         0           0\n",
       "score                0           0\n",
       "timestamp            0           0"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking nulls\n",
    "\n",
    "pd.DataFrame([df_onion.isnull().sum(),df_not_onion.isnull().sum()], index=[\"TheOnion\",\"notheonion\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "ec42660f-9b5b-474e-b505-16ee35a5f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "\n",
    "df_onion.drop_duplicates(subset='title', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "46d1bedc-a7eb-4d61-b93a-40e330725155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "\n",
    "df_not_onion.drop_duplicates(subset='title', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2af984-a641-4b02-8dfa-8166fc8b1810",
   "metadata": {},
   "source": [
    "##### 2b. Title-Punctuation Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "7769b02a-7720-41a8-97b5-67c8a527a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Make text lowercase, remove text in square brackets,remove links,remove punctuation,extra space and remove words containing numbers.\n",
    "\n",
    "def text_cleaning(text):\n",
    "\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[^\\w\\s]', '', text)\n",
    "    text = re.sub('\\[^A-Za-z]', '', text)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>''+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "282d858e-06dc-43d5-a6ae-dd2f785272d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>mothershipq</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>surgeon kind of pissed patient seeing her defo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>-ImYourHuckleberry-</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>mcdonald’s blocked from building drivethrough ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>gwyneth paltrow touts new diamondencrusted tre...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>artist crafting music box hopes it delights at...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>homeowner trying to smoke out snakes accidenta...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit               author               domain  \\\n",
       "0  TheOnion          mothershipq         theonion.com   \n",
       "1  TheOnion  -ImYourHuckleberry-  theartnewspaper.com   \n",
       "2  TheOnion                dwaxe         theonion.com   \n",
       "3  TheOnion                dwaxe         theonion.com   \n",
       "4  TheOnion                dwaxe         theonion.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  surgeon kind of pissed patient seeing her defo...             0      1   \n",
       "1  mcdonald’s blocked from building drivethrough ...             1      1   \n",
       "2  gwyneth paltrow touts new diamondencrusted tre...             0      1   \n",
       "3  artist crafting music box hopes it delights at...             0      1   \n",
       "4  homeowner trying to smoke out snakes accidenta...             0      1   \n",
       "\n",
       "    timestamp  \n",
       "0  2021-12-31  \n",
       "1  2021-12-31  \n",
       "2  2021-12-31  \n",
       "3  2021-12-31  \n",
       "4  2021-12-31  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onion['title']=df_onion['title'].apply(lambda x:text_cleaning(x))\n",
    "df_onion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "7ff19a33-045b-4890-ba55-8662e2aac8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Taco_duck68</td>\n",
       "      <td>wral.com</td>\n",
       "      <td>man attempts to pay for car with rap steals po...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>BlackNingaa</td>\n",
       "      <td>bloodyelbow.com</td>\n",
       "      <td>former ufc fighter reveals past as sex worker ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Lopsided_File_1642</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>log into facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>SkinnyWhiteGirl19</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>mcdonald’s blocked from building drivethrough ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>kids-cake-and-crazy</td>\n",
       "      <td>kjrh.com</td>\n",
       "      <td>legendary actress betty white dies at on new y...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit               author               domain  \\\n",
       "0  nottheonion          Taco_duck68             wral.com   \n",
       "1  nottheonion          BlackNingaa      bloodyelbow.com   \n",
       "2  nottheonion   Lopsided_File_1642         facebook.com   \n",
       "3  nottheonion    SkinnyWhiteGirl19  theartnewspaper.com   \n",
       "4  nottheonion  kids-cake-and-crazy             kjrh.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  man attempts to pay for car with rap steals po...             0      1   \n",
       "1  former ufc fighter reveals past as sex worker ...             1      1   \n",
       "2                                  log into facebook             1      1   \n",
       "3  mcdonald’s blocked from building drivethrough ...             0      1   \n",
       "4  legendary actress betty white dies at on new y...             0      1   \n",
       "\n",
       "    timestamp  \n",
       "0  2021-12-31  \n",
       "1  2021-12-31  \n",
       "2  2021-12-31  \n",
       "3  2021-12-31  \n",
       "4  2021-12-31  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_onion['title']=df_not_onion['title'].apply(lambda x:text_cleaning(x))\n",
    "df_not_onion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf5b7d-c6ce-4964-aaad-242e71997d20",
   "metadata": {},
   "source": [
    "##### 2c. Title-Stop words removing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ef10bb-51cf-402d-935e-fed5428fbe42",
   "metadata": {},
   "source": [
    "A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query. We would not want these words to take up space in our database, or taking up valuable processing time. For this, we can remove them easily, by storing a list of words that you consider to stop words. NLTK(Natural Language Toolkit) in python has a list of stopwords stored in 16 different languages. [Source](https://www.geeksforgeeks.org/removing-stop-words-nltk-python/) : Geeks for Geeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "2ccf60e2-322a-461f-9e30-994854f30a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>mothershipq</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>surgeon kind pissed patient seeing deformed fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>-ImYourHuckleberry-</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>mcdonald’s blocked building drivethrough romes...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>gwyneth paltrow touts new diamondencrusted tre...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>artist crafting music box hopes delights least...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>homeowner trying smoke snakes accidentally bur...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit               author               domain  \\\n",
       "0  TheOnion          mothershipq         theonion.com   \n",
       "1  TheOnion  -ImYourHuckleberry-  theartnewspaper.com   \n",
       "2  TheOnion                dwaxe         theonion.com   \n",
       "3  TheOnion                dwaxe         theonion.com   \n",
       "4  TheOnion                dwaxe         theonion.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  surgeon kind pissed patient seeing deformed fa...             0      1   \n",
       "1  mcdonald’s blocked building drivethrough romes...             1      1   \n",
       "2  gwyneth paltrow touts new diamondencrusted tre...             0      1   \n",
       "3  artist crafting music box hopes delights least...             0      1   \n",
       "4  homeowner trying smoke snakes accidentally bur...             0      1   \n",
       "\n",
       "    timestamp  \n",
       "0  2021-12-31  \n",
       "1  2021-12-31  \n",
       "2  2021-12-31  \n",
       "3  2021-12-31  \n",
       "4  2021-12-31  "
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "df_onion['title'] = df_onion['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df_onion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "868e6db6-0f91-45b3-8130-a01c26a34110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Taco_duck68</td>\n",
       "      <td>wral.com</td>\n",
       "      <td>man attempts pay car rap steals potato chip truck</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>BlackNingaa</td>\n",
       "      <td>bloodyelbow.com</td>\n",
       "      <td>former ufc fighter reveals past sex worker fun...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Lopsided_File_1642</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>log facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>SkinnyWhiteGirl19</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>mcdonald’s blocked building drivethrough romes...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>kids-cake-and-crazy</td>\n",
       "      <td>kjrh.com</td>\n",
       "      <td>legendary actress betty white dies new years e...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit               author               domain  \\\n",
       "0  nottheonion          Taco_duck68             wral.com   \n",
       "1  nottheonion          BlackNingaa      bloodyelbow.com   \n",
       "2  nottheonion   Lopsided_File_1642         facebook.com   \n",
       "3  nottheonion    SkinnyWhiteGirl19  theartnewspaper.com   \n",
       "4  nottheonion  kids-cake-and-crazy             kjrh.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  man attempts pay car rap steals potato chip truck             0      1   \n",
       "1  former ufc fighter reveals past sex worker fun...             1      1   \n",
       "2                                       log facebook             1      1   \n",
       "3  mcdonald’s blocked building drivethrough romes...             0      1   \n",
       "4  legendary actress betty white dies new years e...             0      1   \n",
       "\n",
       "    timestamp  \n",
       "0  2021-12-31  \n",
       "1  2021-12-31  \n",
       "2  2021-12-31  \n",
       "3  2021-12-31  \n",
       "4  2021-12-31  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "df_not_onion['title'] = df_not_onion['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df_not_onion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b300e66b-f4fc-4111-a55f-89b3dea08556",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 2d. Title - Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d086a3-6710-4bbf-931b-2ea3a72ee1af",
   "metadata": {},
   "source": [
    "Tokenization is the process of splitting a text object into smaller units known as tokens. Examples of tokens can be words, characters, numbers, symbols, or n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "9764743d-710f-4df3-a639-9016ad2cc2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = re.split('\\s+' ,text)\n",
    "    return [x.lower() for x in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "a0709587-327f-48b1-ac14-d1f5b81ae708",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>mothershipq</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>surgeon kind pissed patient seeing deformed fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[surgeon, kind, pissed, patient, seeing, defor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>-ImYourHuckleberry-</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>mcdonald’s blocked building drivethrough romes...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[mcdonald’s, blocked, building, drivethrough, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>gwyneth paltrow touts new diamondencrusted tre...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[gwyneth, paltrow, touts, new, diamondencruste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>artist crafting music box hopes delights least...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[artist, crafting, music, box, hopes, delights...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>homeowner trying smoke snakes accidentally bur...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[homeowner, trying, smoke, snakes, accidentall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit               author               domain  \\\n",
       "0  TheOnion          mothershipq         theonion.com   \n",
       "1  TheOnion  -ImYourHuckleberry-  theartnewspaper.com   \n",
       "2  TheOnion                dwaxe         theonion.com   \n",
       "3  TheOnion                dwaxe         theonion.com   \n",
       "4  TheOnion                dwaxe         theonion.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  surgeon kind pissed patient seeing deformed fa...             0      1   \n",
       "1  mcdonald’s blocked building drivethrough romes...             1      1   \n",
       "2  gwyneth paltrow touts new diamondencrusted tre...             0      1   \n",
       "3  artist crafting music box hopes delights least...             0      1   \n",
       "4  homeowner trying smoke snakes accidentally bur...             0      1   \n",
       "\n",
       "    timestamp                                             tokens  \n",
       "0  2021-12-31  [surgeon, kind, pissed, patient, seeing, defor...  \n",
       "1  2021-12-31  [mcdonald’s, blocked, building, drivethrough, ...  \n",
       "2  2021-12-31  [gwyneth, paltrow, touts, new, diamondencruste...  \n",
       "3  2021-12-31  [artist, crafting, music, box, hopes, delights...  \n",
       "4  2021-12-31  [homeowner, trying, smoke, snakes, accidentall...  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onion['tokens'] = df_onion['title'].apply(lambda msg : tokenize(msg))\n",
    "df_onion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "1f77cb72-af00-4520-826e-0bc805344221",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Taco_duck68</td>\n",
       "      <td>wral.com</td>\n",
       "      <td>man attempts pay car rap steals potato chip truck</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[man, attempts, pay, car, rap, steals, potato,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>BlackNingaa</td>\n",
       "      <td>bloodyelbow.com</td>\n",
       "      <td>former ufc fighter reveals past sex worker fun...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[former, ufc, fighter, reveals, past, sex, wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Lopsided_File_1642</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>log facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[log, facebook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>SkinnyWhiteGirl19</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>mcdonald’s blocked building drivethrough romes...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[mcdonald’s, blocked, building, drivethrough, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>kids-cake-and-crazy</td>\n",
       "      <td>kjrh.com</td>\n",
       "      <td>legendary actress betty white dies new years e...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[legendary, actress, betty, white, dies, new, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit               author               domain  \\\n",
       "0  nottheonion          Taco_duck68             wral.com   \n",
       "1  nottheonion          BlackNingaa      bloodyelbow.com   \n",
       "2  nottheonion   Lopsided_File_1642         facebook.com   \n",
       "3  nottheonion    SkinnyWhiteGirl19  theartnewspaper.com   \n",
       "4  nottheonion  kids-cake-and-crazy             kjrh.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  man attempts pay car rap steals potato chip truck             0      1   \n",
       "1  former ufc fighter reveals past sex worker fun...             1      1   \n",
       "2                                       log facebook             1      1   \n",
       "3  mcdonald’s blocked building drivethrough romes...             0      1   \n",
       "4  legendary actress betty white dies new years e...             0      1   \n",
       "\n",
       "    timestamp                                             tokens  \n",
       "0  2021-12-31  [man, attempts, pay, car, rap, steals, potato,...  \n",
       "1  2021-12-31  [former, ufc, fighter, reveals, past, sex, wor...  \n",
       "2  2021-12-31                                    [log, facebook]  \n",
       "3  2021-12-31  [mcdonald’s, blocked, building, drivethrough, ...  \n",
       "4  2021-12-31  [legendary, actress, betty, white, dies, new, ...  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_onion['tokens'] = df_not_onion['title'].apply(lambda msg : tokenize(msg))\n",
    "df_not_onion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "2542c928-1625-46ed-8542-851b940d6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate tokenizer.\n",
    "tokenizer = RegexpTokenizer('[a-z]\\w+')\n",
    "\n",
    "# Run tokenizer.\n",
    "def tokenize_1(text):\n",
    "    text = tokenizer.tokenize(text)\n",
    "    return [x.lower() for x in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "7a4d317d-1220-4c4f-a9fe-4c30423dce5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>mothershipq</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>surgeon kind pissed patient seeing deformed fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[surgeon, kind, pissed, patient, seeing, defor...</td>\n",
       "      <td>[surgeon, kind, pissed, patient, seeing, defor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>-ImYourHuckleberry-</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>mcdonald’s blocked building drivethrough romes...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[mcdonald’s, blocked, building, drivethrough, ...</td>\n",
       "      <td>[mcdonald, blocked, building, drivethrough, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>gwyneth paltrow touts new diamondencrusted tre...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[gwyneth, paltrow, touts, new, diamondencruste...</td>\n",
       "      <td>[gwyneth, paltrow, touts, new, diamondencruste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>artist crafting music box hopes delights least...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[artist, crafting, music, box, hopes, delights...</td>\n",
       "      <td>[artist, crafting, music, box, hopes, delights...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>homeowner trying smoke snakes accidentally bur...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[homeowner, trying, smoke, snakes, accidentall...</td>\n",
       "      <td>[homeowner, trying, smoke, snakes, accidentall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit               author               domain  \\\n",
       "0  TheOnion          mothershipq         theonion.com   \n",
       "1  TheOnion  -ImYourHuckleberry-  theartnewspaper.com   \n",
       "2  TheOnion                dwaxe         theonion.com   \n",
       "3  TheOnion                dwaxe         theonion.com   \n",
       "4  TheOnion                dwaxe         theonion.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  surgeon kind pissed patient seeing deformed fa...             0      1   \n",
       "1  mcdonald’s blocked building drivethrough romes...             1      1   \n",
       "2  gwyneth paltrow touts new diamondencrusted tre...             0      1   \n",
       "3  artist crafting music box hopes delights least...             0      1   \n",
       "4  homeowner trying smoke snakes accidentally bur...             0      1   \n",
       "\n",
       "    timestamp                                             tokens  \\\n",
       "0  2021-12-31  [surgeon, kind, pissed, patient, seeing, defor...   \n",
       "1  2021-12-31  [mcdonald’s, blocked, building, drivethrough, ...   \n",
       "2  2021-12-31  [gwyneth, paltrow, touts, new, diamondencruste...   \n",
       "3  2021-12-31  [artist, crafting, music, box, hopes, delights...   \n",
       "4  2021-12-31  [homeowner, trying, smoke, snakes, accidentall...   \n",
       "\n",
       "                                            tokens_1  \n",
       "0  [surgeon, kind, pissed, patient, seeing, defor...  \n",
       "1  [mcdonald, blocked, building, drivethrough, ro...  \n",
       "2  [gwyneth, paltrow, touts, new, diamondencruste...  \n",
       "3  [artist, crafting, music, box, hopes, delights...  \n",
       "4  [homeowner, trying, smoke, snakes, accidentall...  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onion['tokens_1'] = df_onion['title'].apply(lambda msg : tokenize_1(msg))\n",
    "df_onion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "8a78a83f-b8d0-4ff3-a3bc-9268c41c4847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Taco_duck68</td>\n",
       "      <td>wral.com</td>\n",
       "      <td>man attempts pay car rap steals potato chip truck</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[man, attempts, pay, car, rap, steals, potato,...</td>\n",
       "      <td>[man, attempts, pay, car, rap, steals, potato,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>BlackNingaa</td>\n",
       "      <td>bloodyelbow.com</td>\n",
       "      <td>former ufc fighter reveals past sex worker fun...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[former, ufc, fighter, reveals, past, sex, wor...</td>\n",
       "      <td>[former, ufc, fighter, reveals, past, sex, wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Lopsided_File_1642</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>log facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[log, facebook]</td>\n",
       "      <td>[log, facebook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>SkinnyWhiteGirl19</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>mcdonald’s blocked building drivethrough romes...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[mcdonald’s, blocked, building, drivethrough, ...</td>\n",
       "      <td>[mcdonald, blocked, building, drivethrough, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>kids-cake-and-crazy</td>\n",
       "      <td>kjrh.com</td>\n",
       "      <td>legendary actress betty white dies new years e...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[legendary, actress, betty, white, dies, new, ...</td>\n",
       "      <td>[legendary, actress, betty, white, dies, new, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit               author               domain  \\\n",
       "0  nottheonion          Taco_duck68             wral.com   \n",
       "1  nottheonion          BlackNingaa      bloodyelbow.com   \n",
       "2  nottheonion   Lopsided_File_1642         facebook.com   \n",
       "3  nottheonion    SkinnyWhiteGirl19  theartnewspaper.com   \n",
       "4  nottheonion  kids-cake-and-crazy             kjrh.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  man attempts pay car rap steals potato chip truck             0      1   \n",
       "1  former ufc fighter reveals past sex worker fun...             1      1   \n",
       "2                                       log facebook             1      1   \n",
       "3  mcdonald’s blocked building drivethrough romes...             0      1   \n",
       "4  legendary actress betty white dies new years e...             0      1   \n",
       "\n",
       "    timestamp                                             tokens  \\\n",
       "0  2021-12-31  [man, attempts, pay, car, rap, steals, potato,...   \n",
       "1  2021-12-31  [former, ufc, fighter, reveals, past, sex, wor...   \n",
       "2  2021-12-31                                    [log, facebook]   \n",
       "3  2021-12-31  [mcdonald’s, blocked, building, drivethrough, ...   \n",
       "4  2021-12-31  [legendary, actress, betty, white, dies, new, ...   \n",
       "\n",
       "                                            tokens_1  \n",
       "0  [man, attempts, pay, car, rap, steals, potato,...  \n",
       "1  [former, ufc, fighter, reveals, past, sex, wor...  \n",
       "2                                    [log, facebook]  \n",
       "3  [mcdonald, blocked, building, drivethrough, ro...  \n",
       "4  [legendary, actress, betty, white, dies, new, ...  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_onion['tokens_1'] = df_not_onion['title'].apply(lambda msg : tokenize_1(msg))\n",
    "df_not_onion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bc1984-caec-43f2-9e88-e10e7ccda0e6",
   "metadata": {},
   "source": [
    "##### 2e. Title - Lemmanization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd1f95a-0e8b-4633-a452-4925adf536df",
   "metadata": {},
   "source": [
    "Lemmanization is the process of reducing the word to its root stem for example run, running, runs, runed derived from the same word as run. Basically lemmanise is similiar to steamming which removes the prefix or suffix from word like ing, s, es, etc. NLTK library is used to lemmmanise the words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "bf8894c5-e6bb-4d91-b8da-24d4316d77cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def lemmatize(text):\n",
    "    word_net = WordNetLemmatizer()\n",
    "    return [word_net.lemmatize(word) for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "0467b7b4-181d-446b-93dc-2197b4a0fc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_1</th>\n",
       "      <th>lemma_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>mothershipq</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>surgeon kind pissed patient seeing deformed fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[surgeon, kind, pissed, patient, seeing, defor...</td>\n",
       "      <td>[surgeon, kind, pissed, patient, seeing, defor...</td>\n",
       "      <td>[surgeon, kind, pissed, patient, seeing, defor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>-ImYourHuckleberry-</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>mcdonald’s blocked building drivethrough romes...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[mcdonald’s, blocked, building, drivethrough, ...</td>\n",
       "      <td>[mcdonald, blocked, building, drivethrough, ro...</td>\n",
       "      <td>[mcdonald, blocked, building, drivethrough, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>gwyneth paltrow touts new diamondencrusted tre...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[gwyneth, paltrow, touts, new, diamondencruste...</td>\n",
       "      <td>[gwyneth, paltrow, touts, new, diamondencruste...</td>\n",
       "      <td>[gwyneth, paltrow, tout, new, diamondencrusted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>artist crafting music box hopes delights least...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[artist, crafting, music, box, hopes, delights...</td>\n",
       "      <td>[artist, crafting, music, box, hopes, delights...</td>\n",
       "      <td>[artist, crafting, music, box, hope, delight, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>homeowner trying smoke snakes accidentally bur...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[homeowner, trying, smoke, snakes, accidentall...</td>\n",
       "      <td>[homeowner, trying, smoke, snakes, accidentall...</td>\n",
       "      <td>[homeowner, trying, smoke, snake, accidentally...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit               author               domain  \\\n",
       "0  TheOnion          mothershipq         theonion.com   \n",
       "1  TheOnion  -ImYourHuckleberry-  theartnewspaper.com   \n",
       "2  TheOnion                dwaxe         theonion.com   \n",
       "3  TheOnion                dwaxe         theonion.com   \n",
       "4  TheOnion                dwaxe         theonion.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  surgeon kind pissed patient seeing deformed fa...             0      1   \n",
       "1  mcdonald’s blocked building drivethrough romes...             1      1   \n",
       "2  gwyneth paltrow touts new diamondencrusted tre...             0      1   \n",
       "3  artist crafting music box hopes delights least...             0      1   \n",
       "4  homeowner trying smoke snakes accidentally bur...             0      1   \n",
       "\n",
       "    timestamp                                             tokens  \\\n",
       "0  2021-12-31  [surgeon, kind, pissed, patient, seeing, defor...   \n",
       "1  2021-12-31  [mcdonald’s, blocked, building, drivethrough, ...   \n",
       "2  2021-12-31  [gwyneth, paltrow, touts, new, diamondencruste...   \n",
       "3  2021-12-31  [artist, crafting, music, box, hopes, delights...   \n",
       "4  2021-12-31  [homeowner, trying, smoke, snakes, accidentall...   \n",
       "\n",
       "                                            tokens_1  \\\n",
       "0  [surgeon, kind, pissed, patient, seeing, defor...   \n",
       "1  [mcdonald, blocked, building, drivethrough, ro...   \n",
       "2  [gwyneth, paltrow, touts, new, diamondencruste...   \n",
       "3  [artist, crafting, music, box, hopes, delights...   \n",
       "4  [homeowner, trying, smoke, snakes, accidentall...   \n",
       "\n",
       "                                         lemma_words  \n",
       "0  [surgeon, kind, pissed, patient, seeing, defor...  \n",
       "1  [mcdonald, blocked, building, drivethrough, ro...  \n",
       "2  [gwyneth, paltrow, tout, new, diamondencrusted...  \n",
       "3  [artist, crafting, music, box, hope, delight, ...  \n",
       "4  [homeowner, trying, smoke, snake, accidentally...  "
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply lemmatization on tokens\n",
    "\n",
    "df_onion['lemma_words'] = df_onion['tokens_1'].apply(lambda x : lemmatize(x))\n",
    "df_onion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "98e0787c-41ed-4aa4-a908-49db00098d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_1</th>\n",
       "      <th>lemma_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Taco_duck68</td>\n",
       "      <td>wral.com</td>\n",
       "      <td>man attempts pay car rap steals potato chip truck</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[man, attempts, pay, car, rap, steals, potato,...</td>\n",
       "      <td>[man, attempts, pay, car, rap, steals, potato,...</td>\n",
       "      <td>[man, attempt, pay, car, rap, steal, potato, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>BlackNingaa</td>\n",
       "      <td>bloodyelbow.com</td>\n",
       "      <td>former ufc fighter reveals past sex worker fun...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[former, ufc, fighter, reveals, past, sex, wor...</td>\n",
       "      <td>[former, ufc, fighter, reveals, past, sex, wor...</td>\n",
       "      <td>[former, ufc, fighter, reveals, past, sex, wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Lopsided_File_1642</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>log facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[log, facebook]</td>\n",
       "      <td>[log, facebook]</td>\n",
       "      <td>[log, facebook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>SkinnyWhiteGirl19</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>mcdonald’s blocked building drivethrough romes...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[mcdonald’s, blocked, building, drivethrough, ...</td>\n",
       "      <td>[mcdonald, blocked, building, drivethrough, ro...</td>\n",
       "      <td>[mcdonald, blocked, building, drivethrough, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>kids-cake-and-crazy</td>\n",
       "      <td>kjrh.com</td>\n",
       "      <td>legendary actress betty white dies new years e...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[legendary, actress, betty, white, dies, new, ...</td>\n",
       "      <td>[legendary, actress, betty, white, dies, new, ...</td>\n",
       "      <td>[legendary, actress, betty, white, dy, new, ye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit               author               domain  \\\n",
       "0  nottheonion          Taco_duck68             wral.com   \n",
       "1  nottheonion          BlackNingaa      bloodyelbow.com   \n",
       "2  nottheonion   Lopsided_File_1642         facebook.com   \n",
       "3  nottheonion    SkinnyWhiteGirl19  theartnewspaper.com   \n",
       "4  nottheonion  kids-cake-and-crazy             kjrh.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  man attempts pay car rap steals potato chip truck             0      1   \n",
       "1  former ufc fighter reveals past sex worker fun...             1      1   \n",
       "2                                       log facebook             1      1   \n",
       "3  mcdonald’s blocked building drivethrough romes...             0      1   \n",
       "4  legendary actress betty white dies new years e...             0      1   \n",
       "\n",
       "    timestamp                                             tokens  \\\n",
       "0  2021-12-31  [man, attempts, pay, car, rap, steals, potato,...   \n",
       "1  2021-12-31  [former, ufc, fighter, reveals, past, sex, wor...   \n",
       "2  2021-12-31                                    [log, facebook]   \n",
       "3  2021-12-31  [mcdonald’s, blocked, building, drivethrough, ...   \n",
       "4  2021-12-31  [legendary, actress, betty, white, dies, new, ...   \n",
       "\n",
       "                                            tokens_1  \\\n",
       "0  [man, attempts, pay, car, rap, steals, potato,...   \n",
       "1  [former, ufc, fighter, reveals, past, sex, wor...   \n",
       "2                                    [log, facebook]   \n",
       "3  [mcdonald, blocked, building, drivethrough, ro...   \n",
       "4  [legendary, actress, betty, white, dies, new, ...   \n",
       "\n",
       "                                         lemma_words  \n",
       "0  [man, attempt, pay, car, rap, steal, potato, c...  \n",
       "1  [former, ufc, fighter, reveals, past, sex, wor...  \n",
       "2                                    [log, facebook]  \n",
       "3  [mcdonald, blocked, building, drivethrough, ro...  \n",
       "4  [legendary, actress, betty, white, dy, new, ye...  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_onion['lemma_words'] = df_not_onion['tokens_1'].apply(lambda x : lemmatize(x))\n",
    "df_not_onion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e1ae3-248f-490f-855b-11d4112aab78",
   "metadata": {},
   "source": [
    "##### 2f. Convert words to feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "bf71a9ff-a7dd-4e77-bd81-317bbaa12d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentences to get clean text as input for vectors\n",
    "\n",
    "def return_sentences(tokens):\n",
    "    return \" \".join([word for word in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "065d75e2-4431-4237-b758-b3498df33baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_1</th>\n",
       "      <th>lemma_words</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>mothershipq</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>surgeon kind pissed patient seeing deformed fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[surgeon, kind, pissed, patient, seeing, defor...</td>\n",
       "      <td>[surgeon, kind, pissed, patient, seeing, defor...</td>\n",
       "      <td>[surgeon, kind, pissed, patient, seeing, defor...</td>\n",
       "      <td>surgeon kind pissed patient seeing deformed fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>-ImYourHuckleberry-</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>mcdonald’s blocked building drivethrough romes...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[mcdonald’s, blocked, building, drivethrough, ...</td>\n",
       "      <td>[mcdonald, blocked, building, drivethrough, ro...</td>\n",
       "      <td>[mcdonald, blocked, building, drivethrough, ro...</td>\n",
       "      <td>mcdonald blocked building drivethrough rome an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>gwyneth paltrow touts new diamondencrusted tre...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[gwyneth, paltrow, touts, new, diamondencruste...</td>\n",
       "      <td>[gwyneth, paltrow, touts, new, diamondencruste...</td>\n",
       "      <td>[gwyneth, paltrow, tout, new, diamondencrusted...</td>\n",
       "      <td>gwyneth paltrow tout new diamondencrusted trep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>artist crafting music box hopes delights least...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[artist, crafting, music, box, hopes, delights...</td>\n",
       "      <td>[artist, crafting, music, box, hopes, delights...</td>\n",
       "      <td>[artist, crafting, music, box, hope, delight, ...</td>\n",
       "      <td>artist crafting music box hope delight least o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>homeowner trying smoke snakes accidentally bur...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[homeowner, trying, smoke, snakes, accidentall...</td>\n",
       "      <td>[homeowner, trying, smoke, snakes, accidentall...</td>\n",
       "      <td>[homeowner, trying, smoke, snake, accidentally...</td>\n",
       "      <td>homeowner trying smoke snake accidentally burn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit               author               domain  \\\n",
       "0  TheOnion          mothershipq         theonion.com   \n",
       "1  TheOnion  -ImYourHuckleberry-  theartnewspaper.com   \n",
       "2  TheOnion                dwaxe         theonion.com   \n",
       "3  TheOnion                dwaxe         theonion.com   \n",
       "4  TheOnion                dwaxe         theonion.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  surgeon kind pissed patient seeing deformed fa...             0      1   \n",
       "1  mcdonald’s blocked building drivethrough romes...             1      1   \n",
       "2  gwyneth paltrow touts new diamondencrusted tre...             0      1   \n",
       "3  artist crafting music box hopes delights least...             0      1   \n",
       "4  homeowner trying smoke snakes accidentally bur...             0      1   \n",
       "\n",
       "    timestamp                                             tokens  \\\n",
       "0  2021-12-31  [surgeon, kind, pissed, patient, seeing, defor...   \n",
       "1  2021-12-31  [mcdonald’s, blocked, building, drivethrough, ...   \n",
       "2  2021-12-31  [gwyneth, paltrow, touts, new, diamondencruste...   \n",
       "3  2021-12-31  [artist, crafting, music, box, hopes, delights...   \n",
       "4  2021-12-31  [homeowner, trying, smoke, snakes, accidentall...   \n",
       "\n",
       "                                            tokens_1  \\\n",
       "0  [surgeon, kind, pissed, patient, seeing, defor...   \n",
       "1  [mcdonald, blocked, building, drivethrough, ro...   \n",
       "2  [gwyneth, paltrow, touts, new, diamondencruste...   \n",
       "3  [artist, crafting, music, box, hopes, delights...   \n",
       "4  [homeowner, trying, smoke, snakes, accidentall...   \n",
       "\n",
       "                                         lemma_words  \\\n",
       "0  [surgeon, kind, pissed, patient, seeing, defor...   \n",
       "1  [mcdonald, blocked, building, drivethrough, ro...   \n",
       "2  [gwyneth, paltrow, tout, new, diamondencrusted...   \n",
       "3  [artist, crafting, music, box, hope, delight, ...   \n",
       "4  [homeowner, trying, smoke, snake, accidentally...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  surgeon kind pissed patient seeing deformed fa...  \n",
       "1  mcdonald blocked building drivethrough rome an...  \n",
       "2  gwyneth paltrow tout new diamondencrusted trep...  \n",
       "3  artist crafting music box hope delight least o...  \n",
       "4  homeowner trying smoke snake accidentally burn...  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onion['clean_text'] = df_onion['lemma_words'].apply(lambda x : return_sentences(x))\n",
    "df_onion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "3a7cf8f5-cca3-4e9a-8cf7-78b69c8e4d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_1</th>\n",
       "      <th>lemma_words</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Taco_duck68</td>\n",
       "      <td>wral.com</td>\n",
       "      <td>man attempts pay car rap steals potato chip truck</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[man, attempts, pay, car, rap, steals, potato,...</td>\n",
       "      <td>[man, attempts, pay, car, rap, steals, potato,...</td>\n",
       "      <td>[man, attempt, pay, car, rap, steal, potato, c...</td>\n",
       "      <td>man attempt pay car rap steal potato chip truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>BlackNingaa</td>\n",
       "      <td>bloodyelbow.com</td>\n",
       "      <td>former ufc fighter reveals past sex worker fun...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[former, ufc, fighter, reveals, past, sex, wor...</td>\n",
       "      <td>[former, ufc, fighter, reveals, past, sex, wor...</td>\n",
       "      <td>[former, ufc, fighter, reveals, past, sex, wor...</td>\n",
       "      <td>former ufc fighter reveals past sex worker fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Lopsided_File_1642</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>log facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[log, facebook]</td>\n",
       "      <td>[log, facebook]</td>\n",
       "      <td>[log, facebook]</td>\n",
       "      <td>log facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>SkinnyWhiteGirl19</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>mcdonald’s blocked building drivethrough romes...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[mcdonald’s, blocked, building, drivethrough, ...</td>\n",
       "      <td>[mcdonald, blocked, building, drivethrough, ro...</td>\n",
       "      <td>[mcdonald, blocked, building, drivethrough, ro...</td>\n",
       "      <td>mcdonald blocked building drivethrough rome an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>kids-cake-and-crazy</td>\n",
       "      <td>kjrh.com</td>\n",
       "      <td>legendary actress betty white dies new years e...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[legendary, actress, betty, white, dies, new, ...</td>\n",
       "      <td>[legendary, actress, betty, white, dies, new, ...</td>\n",
       "      <td>[legendary, actress, betty, white, dy, new, ye...</td>\n",
       "      <td>legendary actress betty white dy new year eve ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit               author               domain  \\\n",
       "0  nottheonion          Taco_duck68             wral.com   \n",
       "1  nottheonion          BlackNingaa      bloodyelbow.com   \n",
       "2  nottheonion   Lopsided_File_1642         facebook.com   \n",
       "3  nottheonion    SkinnyWhiteGirl19  theartnewspaper.com   \n",
       "4  nottheonion  kids-cake-and-crazy             kjrh.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  man attempts pay car rap steals potato chip truck             0      1   \n",
       "1  former ufc fighter reveals past sex worker fun...             1      1   \n",
       "2                                       log facebook             1      1   \n",
       "3  mcdonald’s blocked building drivethrough romes...             0      1   \n",
       "4  legendary actress betty white dies new years e...             0      1   \n",
       "\n",
       "    timestamp                                             tokens  \\\n",
       "0  2021-12-31  [man, attempts, pay, car, rap, steals, potato,...   \n",
       "1  2021-12-31  [former, ufc, fighter, reveals, past, sex, wor...   \n",
       "2  2021-12-31                                    [log, facebook]   \n",
       "3  2021-12-31  [mcdonald’s, blocked, building, drivethrough, ...   \n",
       "4  2021-12-31  [legendary, actress, betty, white, dies, new, ...   \n",
       "\n",
       "                                            tokens_1  \\\n",
       "0  [man, attempts, pay, car, rap, steals, potato,...   \n",
       "1  [former, ufc, fighter, reveals, past, sex, wor...   \n",
       "2                                    [log, facebook]   \n",
       "3  [mcdonald, blocked, building, drivethrough, ro...   \n",
       "4  [legendary, actress, betty, white, dies, new, ...   \n",
       "\n",
       "                                         lemma_words  \\\n",
       "0  [man, attempt, pay, car, rap, steal, potato, c...   \n",
       "1  [former, ufc, fighter, reveals, past, sex, wor...   \n",
       "2                                    [log, facebook]   \n",
       "3  [mcdonald, blocked, building, drivethrough, ro...   \n",
       "4  [legendary, actress, betty, white, dy, new, ye...   \n",
       "\n",
       "                                          clean_text  \n",
       "0    man attempt pay car rap steal potato chip truck  \n",
       "1  former ufc fighter reveals past sex worker fun...  \n",
       "2                                       log facebook  \n",
       "3  mcdonald blocked building drivethrough rome an...  \n",
       "4  legendary actress betty white dy new year eve ...  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_onion['clean_text'] = df_not_onion['lemma_words'].apply(lambda x : return_sentences(x))\n",
    "df_not_onion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c35955d-39d8-4104-b64b-e4dff85a6381",
   "metadata": {},
   "source": [
    "##### 2g. Drop the row if clean_text with NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "def538ba-8320-44c1-a52c-3a54e1777f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_to_nan (value):\n",
    "    if value == '':\n",
    "        print (value)\n",
    "        return np.nan\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "7790c4b3-5573-471e-9585-8b250be01eb9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_onion['clean_text'] = df_onion['clean_text'].apply(change_to_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "f2955b84-b7c5-4b2a-a860-72334bd3eb0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_1</th>\n",
       "      <th>lemma_words</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>mothershipq</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>surgeon kind pissed patient seeing deformed fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[surgeon, kind, pissed, patient, seeing, defor...</td>\n",
       "      <td>[surgeon, kind, pissed, patient, seeing, defor...</td>\n",
       "      <td>[surgeon, kind, pissed, patient, seeing, defor...</td>\n",
       "      <td>surgeon kind pissed patient seeing deformed fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>-ImYourHuckleberry-</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>mcdonald’s blocked building drivethrough romes...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[mcdonald’s, blocked, building, drivethrough, ...</td>\n",
       "      <td>[mcdonald, blocked, building, drivethrough, ro...</td>\n",
       "      <td>[mcdonald, blocked, building, drivethrough, ro...</td>\n",
       "      <td>mcdonald blocked building drivethrough rome an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>gwyneth paltrow touts new diamondencrusted tre...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[gwyneth, paltrow, touts, new, diamondencruste...</td>\n",
       "      <td>[gwyneth, paltrow, touts, new, diamondencruste...</td>\n",
       "      <td>[gwyneth, paltrow, tout, new, diamondencrusted...</td>\n",
       "      <td>gwyneth paltrow tout new diamondencrusted trep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>artist crafting music box hopes delights least...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[artist, crafting, music, box, hopes, delights...</td>\n",
       "      <td>[artist, crafting, music, box, hopes, delights...</td>\n",
       "      <td>[artist, crafting, music, box, hope, delight, ...</td>\n",
       "      <td>artist crafting music box hope delight least o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>theonion.com</td>\n",
       "      <td>homeowner trying smoke snakes accidentally bur...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[homeowner, trying, smoke, snakes, accidentall...</td>\n",
       "      <td>[homeowner, trying, smoke, snakes, accidentall...</td>\n",
       "      <td>[homeowner, trying, smoke, snake, accidentally...</td>\n",
       "      <td>homeowner trying smoke snake accidentally burn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit               author               domain  \\\n",
       "0  TheOnion          mothershipq         theonion.com   \n",
       "1  TheOnion  -ImYourHuckleberry-  theartnewspaper.com   \n",
       "2  TheOnion                dwaxe         theonion.com   \n",
       "3  TheOnion                dwaxe         theonion.com   \n",
       "4  TheOnion                dwaxe         theonion.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  surgeon kind pissed patient seeing deformed fa...             0      1   \n",
       "1  mcdonald’s blocked building drivethrough romes...             1      1   \n",
       "2  gwyneth paltrow touts new diamondencrusted tre...             0      1   \n",
       "3  artist crafting music box hopes delights least...             0      1   \n",
       "4  homeowner trying smoke snakes accidentally bur...             0      1   \n",
       "\n",
       "    timestamp                                             tokens  \\\n",
       "0  2021-12-31  [surgeon, kind, pissed, patient, seeing, defor...   \n",
       "1  2021-12-31  [mcdonald’s, blocked, building, drivethrough, ...   \n",
       "2  2021-12-31  [gwyneth, paltrow, touts, new, diamondencruste...   \n",
       "3  2021-12-31  [artist, crafting, music, box, hopes, delights...   \n",
       "4  2021-12-31  [homeowner, trying, smoke, snakes, accidentall...   \n",
       "\n",
       "                                            tokens_1  \\\n",
       "0  [surgeon, kind, pissed, patient, seeing, defor...   \n",
       "1  [mcdonald, blocked, building, drivethrough, ro...   \n",
       "2  [gwyneth, paltrow, touts, new, diamondencruste...   \n",
       "3  [artist, crafting, music, box, hopes, delights...   \n",
       "4  [homeowner, trying, smoke, snakes, accidentall...   \n",
       "\n",
       "                                         lemma_words  \\\n",
       "0  [surgeon, kind, pissed, patient, seeing, defor...   \n",
       "1  [mcdonald, blocked, building, drivethrough, ro...   \n",
       "2  [gwyneth, paltrow, tout, new, diamondencrusted...   \n",
       "3  [artist, crafting, music, box, hope, delight, ...   \n",
       "4  [homeowner, trying, smoke, snake, accidentally...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  surgeon kind pissed patient seeing deformed fa...  \n",
       "1  mcdonald blocked building drivethrough rome an...  \n",
       "2  gwyneth paltrow tout new diamondencrusted trep...  \n",
       "3  artist crafting music box hope delight least o...  \n",
       "4  homeowner trying smoke snake accidentally burn...  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onion.dropna(subset=['clean_text'], how='all',inplace=True)\n",
    "df_onion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "cf378654-c808-462f-8b7b-72a707f0f203",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_not_onion['clean_text'] = df_not_onion['clean_text'].apply(change_to_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "f3f533a7-4752-4092-a365-a00be6451de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_1</th>\n",
       "      <th>lemma_words</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Taco_duck68</td>\n",
       "      <td>wral.com</td>\n",
       "      <td>man attempts pay car rap steals potato chip truck</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[man, attempts, pay, car, rap, steals, potato,...</td>\n",
       "      <td>[man, attempts, pay, car, rap, steals, potato,...</td>\n",
       "      <td>[man, attempt, pay, car, rap, steal, potato, c...</td>\n",
       "      <td>man attempt pay car rap steal potato chip truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>BlackNingaa</td>\n",
       "      <td>bloodyelbow.com</td>\n",
       "      <td>former ufc fighter reveals past sex worker fun...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[former, ufc, fighter, reveals, past, sex, wor...</td>\n",
       "      <td>[former, ufc, fighter, reveals, past, sex, wor...</td>\n",
       "      <td>[former, ufc, fighter, reveals, past, sex, wor...</td>\n",
       "      <td>former ufc fighter reveals past sex worker fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Lopsided_File_1642</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>log facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[log, facebook]</td>\n",
       "      <td>[log, facebook]</td>\n",
       "      <td>[log, facebook]</td>\n",
       "      <td>log facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>SkinnyWhiteGirl19</td>\n",
       "      <td>theartnewspaper.com</td>\n",
       "      <td>mcdonald’s blocked building drivethrough romes...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[mcdonald’s, blocked, building, drivethrough, ...</td>\n",
       "      <td>[mcdonald, blocked, building, drivethrough, ro...</td>\n",
       "      <td>[mcdonald, blocked, building, drivethrough, ro...</td>\n",
       "      <td>mcdonald blocked building drivethrough rome an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>kids-cake-and-crazy</td>\n",
       "      <td>kjrh.com</td>\n",
       "      <td>legendary actress betty white dies new years e...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>[legendary, actress, betty, white, dies, new, ...</td>\n",
       "      <td>[legendary, actress, betty, white, dies, new, ...</td>\n",
       "      <td>[legendary, actress, betty, white, dy, new, ye...</td>\n",
       "      <td>legendary actress betty white dy new year eve ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit               author               domain  \\\n",
       "0  nottheonion          Taco_duck68             wral.com   \n",
       "1  nottheonion          BlackNingaa      bloodyelbow.com   \n",
       "2  nottheonion   Lopsided_File_1642         facebook.com   \n",
       "3  nottheonion    SkinnyWhiteGirl19  theartnewspaper.com   \n",
       "4  nottheonion  kids-cake-and-crazy             kjrh.com   \n",
       "\n",
       "                                               title  num_comments  score  \\\n",
       "0  man attempts pay car rap steals potato chip truck             0      1   \n",
       "1  former ufc fighter reveals past sex worker fun...             1      1   \n",
       "2                                       log facebook             1      1   \n",
       "3  mcdonald’s blocked building drivethrough romes...             0      1   \n",
       "4  legendary actress betty white dies new years e...             0      1   \n",
       "\n",
       "    timestamp                                             tokens  \\\n",
       "0  2021-12-31  [man, attempts, pay, car, rap, steals, potato,...   \n",
       "1  2021-12-31  [former, ufc, fighter, reveals, past, sex, wor...   \n",
       "2  2021-12-31                                    [log, facebook]   \n",
       "3  2021-12-31  [mcdonald’s, blocked, building, drivethrough, ...   \n",
       "4  2021-12-31  [legendary, actress, betty, white, dies, new, ...   \n",
       "\n",
       "                                            tokens_1  \\\n",
       "0  [man, attempts, pay, car, rap, steals, potato,...   \n",
       "1  [former, ufc, fighter, reveals, past, sex, wor...   \n",
       "2                                    [log, facebook]   \n",
       "3  [mcdonald, blocked, building, drivethrough, ro...   \n",
       "4  [legendary, actress, betty, white, dies, new, ...   \n",
       "\n",
       "                                         lemma_words  \\\n",
       "0  [man, attempt, pay, car, rap, steal, potato, c...   \n",
       "1  [former, ufc, fighter, reveals, past, sex, wor...   \n",
       "2                                    [log, facebook]   \n",
       "3  [mcdonald, blocked, building, drivethrough, ro...   \n",
       "4  [legendary, actress, betty, white, dy, new, ye...   \n",
       "\n",
       "                                          clean_text  \n",
       "0    man attempt pay car rap steal potato chip truck  \n",
       "1  former ufc fighter reveals past sex worker fun...  \n",
       "2                                       log facebook  \n",
       "3  mcdonald blocked building drivethrough rome an...  \n",
       "4  legendary actress betty white dy new year eve ...  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_onion.dropna(subset=['clean_text'], how='all',inplace=True)\n",
    "df_not_onion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "a5f00741-b60e-4a22-91c0-aa488c86796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to csv\n",
    "\n",
    "df_onion.to_csv('processed_onion.csv', index=False)\n",
    "df_not_onion.to_csv('processed_notonion.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
